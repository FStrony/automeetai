# Import necessary packages.
# Ideally, you should import only the required parts of a library,
# but for this script, we assume OpenAI is imported correctly.
from openai import OpenAI


def generate_response(openai_client, system_prompt_text, user_prompt_text):
    """
    This function sends a request to the OpenAI API with a given prompt and returns the model's response.

    Arguments:
    - system_prompt_text: A string containing the system-level instructions for the assistant.
    - user_prompt_text: A string containing the user's input prompt.

    Returns:
    - The content of the response generated by the model.
    """

    try:
        # Create a response using the OpenAI API client for chat models
        response = openai_client.chat.completions.create(
            model="gpt-4o-2024-08-06",  # Specifies the language model to use.
                                        # In this case, it's a GPT-4 variant optimized for chat.
                                        # Different models may have different capabilities and pricing.
            messages=[
                {"role": "system", "content": system_prompt_text},
                {"role": "user", "content": user_prompt_text}
            ],
            # The 'messages' list provides the conversation history.
            # Each message has a 'role' and 'content':
            # - 'system' sets the behavior or tone of the assistant.
            # - 'user' contains the user's question or command.

            # max_tokens=150,  # (Optional) Maximum number of tokens in the response.
                              # Tokens are chunks of words; setting a limit helps control cost and output length.

            temperature=0.7  # Controls the "creativity" or randomness of the response.
                             # Lower values (e.g., 0.2) make output more focused and deterministic.
                             # Higher values (e.g., 1.0) make output more diverse and creative.
                             # 0.7 is a good balance.
        )

        # Extract the generated text from the response object
        returned_text = response.choices[0].message.content.strip()

        # Return the model's response for further use
        return returned_text

    except Exception as e:
        # Handle exceptions that may occur during the API request
        # This can include network issues, invalid API keys, etc.
        print("An error occurred:", str(e))
        return None


# Check if the script is being run directly (not imported as a module)
if __name__ == "__main__":

    # Initialize the OpenAI client with your API key.
    # This enables access to the models provided by OpenAI.
    openai_client = OpenAI(api_key='')  # Make sure to replace this with a valid API key.

    # Define the prompts for testing the function
    system_prompt_text = "You are a helpful assistant."
    user_prompt_text = "Explain the theory of relativity in simple terms."

    # Call the response generation function and capture the result
    result = generate_response(openai_client, system_prompt_text, user_prompt_text)

    # Check if a valid response was returned and print the final result
    if result:
        print("Final Result:", result)
    else:
        print("Failed to get a response from the model.")
